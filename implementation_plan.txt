# EPG Database Implementation Plan

## Project Structure
```
epg_service/
├── src/
│   ├── __init__.py
│   ├── main.py                 # Application entry point
│   ├── config.py               # Configuration management
│   ├── database/
│   │   ├── __init__.py
│   │   ├── schema.py           # Database schema and migrations
│   │   ├── models.py           # Data models (dataclasses)
│   │   └── connection.py       # Connection pooling and management
│   ├── services/
│   │   ├── __init__.py
│   │   ├── epg_service.py      # EPG query operations
│   │   ├── import_service.py   # XMLTV import logic
│   │   ├── cleanup_service.py  # Data retention management
│   │   └── provider_service.py # Provider CRUD operations
│   ├── parsers/
│   │   ├── __init__.py
│   │   └── xmltv_parser.py     # Streaming XMLTV parser
│   ├── api/
│   │   ├── __init__.py
│   │   ├── server.py           # HTTP server setup
│   │   ├── handlers.py         # Request handlers
│   │   └── middleware.py       # Logging, error handling
│   └── scheduler/
│       ├── __init__.py
│       └── jobs.py             # Background job scheduler
├── tests/
│   ├── __init__.py
│   ├── test_epg_service.py
│   ├── test_import_service.py
│   ├── test_xmltv_parser.py
│   └── fixtures/
│       └── sample.xmltv
├── config.yaml                 # Default configuration
├── requirements.txt
└── README.md
```

## Phase 1: Foundation (Database & Models)

### 1.1 Database Schema (`database/schema.py`)
```sql
-- Providers table
CREATE TABLE providers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    xmltv_url TEXT NOT NULL,
    enabled INTEGER DEFAULT 1,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL
);

-- Logical channels (user-facing)
CREATE TABLE channels (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    display_name TEXT NOT NULL,
    icon_url TEXT,
    created_at TEXT NOT NULL,
    UNIQUE(name)
);

-- Map provider channel IDs to logical channels
CREATE TABLE channel_mappings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    provider_id INTEGER NOT NULL,
    provider_channel_id TEXT NOT NULL,
    channel_id INTEGER NOT NULL,
    created_at TEXT NOT NULL,
    FOREIGN KEY (provider_id) REFERENCES providers(id) ON DELETE CASCADE,
    FOREIGN KEY (channel_id) REFERENCES channels(id) ON DELETE CASCADE,
    UNIQUE(provider_id, provider_channel_id)
);

-- EPG program data
CREATE TABLE programs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    channel_id INTEGER NOT NULL,
    provider_id INTEGER NOT NULL,
    start_time TEXT NOT NULL,
    end_time TEXT NOT NULL,
    title TEXT NOT NULL,
    subtitle TEXT,
    description TEXT,
    category TEXT,
    episode_num TEXT,
    rating TEXT,
    actors TEXT,
    directors TEXT,
    icon_url TEXT,
    created_at TEXT NOT NULL,
    FOREIGN KEY (channel_id) REFERENCES channels(id) ON DELETE CASCADE,
    FOREIGN KEY (provider_id) REFERENCES providers(id) ON DELETE CASCADE
);

-- Composite index for efficient time-range queries
CREATE INDEX idx_programs_channel_time ON programs(channel_id, start_time, end_time);
CREATE INDEX idx_programs_provider_time ON programs(provider_id, start_time);

-- Import tracking
CREATE TABLE import_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    provider_id INTEGER NOT NULL,
    started_at TEXT NOT NULL,
    completed_at TEXT,
    status TEXT NOT NULL, -- 'running', 'success', 'failed'
    programs_imported INTEGER DEFAULT 0,
    programs_skipped INTEGER DEFAULT 0,
    error_message TEXT,
    FOREIGN KEY (provider_id) REFERENCES providers(id) ON DELETE CASCADE
);

CREATE INDEX idx_import_log_provider ON import_log(provider_id, completed_at);
```

### 1.2 Data Models (`database/models.py`)
- Provider
- Channel
- ChannelMapping
- Program
- ImportLog

Using `@dataclass` for clean, typed models

### 1.3 Connection Management (`database/connection.py`)
- Thread-safe connection handling
- Connection pooling for concurrent requests
- Migration runner

## Phase 2: Core Services

### 2.1 EPG Service (`services/epg_service.py`)
**Responsibilities:**
- Query programs by channel and time range
- List channels
- Handle SQLite date/time filtering efficiently

**Key Methods:**
- `get_programs(channel_id: int, start: datetime, end: datetime) -> List[Program]`
- `get_channel(channel_id: int) -> Optional[Channel]`
- `list_channels() -> List[Channel]`

### 2.2 Provider Service (`services/provider_service.py`)
**Responsibilities:**
- CRUD operations for providers
- List all providers
- Enable/disable providers

**Key Methods:**
- `create_provider(name: str, xmltv_url: str) -> Provider`
- `update_provider(id: int, **kwargs) -> Provider`
- `delete_provider(id: int) -> bool`
- `list_providers(enabled_only: bool = False) -> List[Provider]`
- `get_provider(id: int) -> Optional[Provider]`

### 2.3 Import Service (`services/import_service.py`)
**Responsibilities:**
- Download XMLTV from provider URLs
- Coordinate parsing and database insertion
- Handle import logging and error recovery
- Detect duplicates (channel_id + start_time)
- Batch inserts for performance

**Key Methods:**
- `import_provider(provider_id: int) -> ImportLog`
- `import_all_providers() -> List[ImportLog]`
- `_download_xmltv(url: str) -> str` (returns file path)
- `_process_programs(provider_id: int, programs: Iterator[Program]) -> tuple[int, int]`

**Import Strategy:**
1. Create import_log entry with status='running'
2. Download XMLTV file
3. Stream parse with xmltv_parser
4. Resolve channel mappings
5. Batch insert programs (INSERT OR IGNORE based on channel_id+start_time)
6. Update import_log with results
7. Clean up temporary files

### 2.4 Cleanup Service (`services/cleanup_service.py`)
**Responsibilities:**
- Delete programs outside retention window
- Run after imports or on schedule

**Key Methods:**
- `cleanup_old_programs(retention_days: int) -> int` (returns deleted count)
- Calculate cutoff dates (past X days, future X days)

**Cleanup Strategy:**
```sql
DELETE FROM programs
WHERE start_time < date('now', '-{days} days')
   OR start_time > date('now', '+{days} days')
```

## Phase 3: XMLTV Parser

### 3.1 XMLTV Parser (`parsers/xmltv_parser.py`)
**Responsibilities:**
- Stream parse XMLTV (xml.etree.ElementTree.iterparse)
- Extract channel and program data
- Handle malformed XML gracefully
- Memory efficient (don't load entire file)

**Key Methods:**
- `parse_channels(file_path: str) -> Iterator[tuple[str, dict]]`
- `parse_programs(file_path: str) -> Iterator[dict]`

**Data Extraction:**
- Channel: id, display-name, icon
- Program: start, stop, channel, title, sub-title, desc, category, episode-num, rating, credits (actors, directors), icon

## Phase 4: API Layer

### 4.1 HTTP Server (`api/server.py`)
**Framework:** Flask (lightweight, production-ready with gunicorn)
- WSGI compatible
- Easy routing
- Good middleware support
- Extensive deployment options

### 4.2 Request Handlers (`api/handlers.py`)
**Endpoints:**

```
GET /api/v1/channels
  Response: [{"id": 1, "name": "...", "display_name": "..."}]

GET /api/v1/channels/{id}/programs?start=2025-01-01T00:00:00Z&end=2025-01-02T00:00:00Z
  Response: [{"id": 1, "title": "...", "start_time": "...", ...}]

GET /api/v1/providers
  Response: [{"id": 1, "name": "...", "enabled": true}]

POST /api/v1/providers
  Body: {"name": "...", "xmltv_url": "..."}
  Response: {"id": 1, ...}

PUT /api/v1/providers/{id}
  Body: {"name": "...", "xmltv_url": "...", "enabled": true}
  Response: {"id": 1, ...}

DELETE /api/v1/providers/{id}
  Response: 204 No Content

POST /api/v1/import/trigger (admin endpoint)
  Response: {"message": "Import started"}
```

**Features:**
- ISO 8601 datetime parsing
- JSON responses
- HTTP error codes (400, 404, 500)
- Request validation

### 4.3 Middleware (`api/middleware.py`)
- Request logging
- Error handling and formatting
- CORS headers (if needed)
- Request timing

## Phase 5: Scheduler

### 5.1 Background Jobs (`scheduler/jobs.py`)
**Framework:** APScheduler (Python native, no external dependencies)

**Jobs:**
1. **Daily Import Job**:
   - Runs at configured time (e.g., 3 AM)
   - Calls `import_service.import_all_providers()`

2. **Cleanup Job**:
   - Runs after imports
   - Calls `cleanup_service.cleanup_old_programs(retention_days)`

**Configuration:**
- Cron-style scheduling
- Configurable times
- Error handling and retry logic

## Phase 6: Configuration & Main

### 6.1 Configuration (`config.py`)
**Config File (YAML):**
```yaml
database:
  path: "epg.db"

server:
  host: "0.0.0.0"
  port: 8080
  debug: false

retention:
  days: 7

scheduler:
  import_time: "03:00"
  timezone: "UTC"

logging:
  level: "INFO"
  format: "json"
```

**Environment Variables Override:**
- `EPG_DB_PATH`
- `EPG_SERVER_PORT`
- `EPG_RETENTION_DAYS`
- etc.

### 6.2 Main Entry Point (`main.py`)
**Responsibilities:**
- Load configuration
- Initialize database
- Start scheduler
- Start HTTP server
- Graceful shutdown handling

## Phase 7: Testing & Documentation

### 7.1 Unit Tests
- Test each service independently
- Mock database calls
- Test XMLTV parser with sample files
- Test API endpoints

### 7.2 Integration Tests
- Full import workflow
- API query performance
- Cleanup verification

### 7.3 Documentation
- README with setup instructions
- API documentation
- Configuration guide
- Deployment guide (systemd, Docker)

## Dependencies

```
Flask==3.0.0
APScheduler==3.10.4
PyYAML==6.0.1
requests==2.31.0
python-dateutil==2.8.2
gunicorn==21.2.0  # for production
```

## Implementation Order

1. **Day 1**: Database schema, models, connection management
2. **Day 2**: EPG service, Provider service
3. **Day 3**: XMLTV parser, Import service
4. **Day 4**: Cleanup service, Scheduler
5. **Day 5**: API layer (Flask, handlers)
6. **Day 6**: Configuration, Main entry point, Integration
7. **Day 7**: Testing, Documentation, Polish

## Production Considerations

- **Deployment**: systemd service or Docker container
- **Monitoring**: Health check endpoint (`GET /health`)
- **Logging**: Structured JSON logs for parsing
- **Backup**: Regular SQLite database backups
- **Performance**: SQLite WAL mode for better concurrency
- **Security**: API authentication (future enhancement)

## Future Enhancements (Out of Scope)

- Channel mapping API endpoints
- Full-text search on program titles/descriptions
- Caching layer (Redis)
- Multiple database backends
- Metrics and monitoring (Prometheus)
- Admin UI